{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8e955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 23:11:36.761142: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 23:11:36.919736: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 23:11:36.921564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 23:11:38.101809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import Mean\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f811bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model \n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('tokenizer_2.pkl', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "tokenizer = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63fb3900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 07:49:05.804983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:49:05.809768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:49:05.812768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-26 07:49:06.136183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:49:06.138879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:49:06.141395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# load the model \n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('model_2.pkl', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "model = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce89c2c",
   "metadata": {},
   "source": [
    "- Enter schedule type: full-time\n",
    "- Enter search term: data analysis\n",
    "- Enter search location: United-State\n",
    "- Enter description tokens: python, scala, excel \n",
    "- Enter year: 2022\n",
    "- Enter month: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f418e",
   "metadata": {},
   "source": [
    "Layers model 1st : \n",
    "\n",
    "- layer: input_24\n",
    "- layer: input_23\n",
    "- layer: embedding_11\n",
    "- layer: lstm_22\n",
    "- layer: lstm_23\n",
    "- layer: dense_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2fb612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: input_6\n",
      "layer: input_5\n",
      "layer: embedding_1\n",
      "layer: lstm_2\n",
      "layer: lstm_3\n",
      "layer: dense_1\n"
     ]
    }
   ],
   "source": [
    "# Print the list of layer names\n",
    "for layer in model.layers:\n",
    "    print(f'layer: {layer.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cba85942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 07:51:08.008309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:51:08.011126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:51:08.013396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-26 07:51:08.293523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:51:08.296058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:51:08.298311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-26 07:51:08.601005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:51:08.603524: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:51:08.605771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 6\n",
    "encoder_inputs = model.get_layer('input_6').input\n",
    "encoder_lstm = model.get_layer('lstm_2')\n",
    "encoder_embedding = model.get_layer('embedding_1')(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = model.get_layer('input_5').input\n",
    "decoder_lstm = model.get_layer('lstm_3')\n",
    "decoder_embedding = model.get_layer('embedding_1')(decoder_inputs)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = model.get_layer('dense_1')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Create the encoder and decoder models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_states_inputs = [Input(shape=(latent_dim,)), Input(shape=(latent_dim,))]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "\n",
    "def generate_text(input_sequence):\n",
    "    states_value = encoder_model.predict(input_sequence)\n",
    "    target_sequence = np.zeros((1, 1))  # Start with empty target sequence\n",
    "    confidence_threshold = 0.00011\n",
    "\n",
    "    stop_condition = False\n",
    "    generated_text = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_sequence] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        # Check if the sampled token index exists in the vocabulary\n",
    "        if sampled_token_index in tokenizer.index_word:\n",
    "            sampled_word = tokenizer.index_word[sampled_token_index]\n",
    "            generated_text.append(sampled_word)\n",
    "            print(np.max(output_tokens))\n",
    "        else:\n",
    "            # Handle the case when the token index is not found\n",
    "            remaining_indices = set(range(len(tokenizer.index_word))) - {0}  # Exclude the unknown token\n",
    "            if len(remaining_indices) > 0:\n",
    "                sampled_token_index = np.random.choice(list(remaining_indices))\n",
    "                sampled_word = tokenizer.index_word[sampled_token_index]\n",
    "                generated_text.append(sampled_word)\n",
    "                print(np.max(output_tokens))\n",
    "            else:\n",
    "                # Handle the case when no valid token indices are available\n",
    "                sampled_word = '<unknown>'\n",
    "                generated_text.append(sampled_word)\n",
    "                print('No valid token indices available.')\n",
    "\n",
    "        # Update the stop condition based on the generated token\n",
    "        if sampled_word == '<end>' or len(generated_text) > 100:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_sequence = np.array([[sampled_token_index]])  # Update the target sequence\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938e26ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter schedule type: full-time\n",
      "Enter search term: data analysis\n",
      "Enter search location: United-State\n",
      "Enter description tokens: python, scala, excel\n",
      "Enter year: 2023\n",
      "Enter month: 12\n"
     ]
    }
   ],
   "source": [
    "# Get user inputs\n",
    "feature_1 = input(\"Enter schedule type: \")\n",
    "feature_2 = input(\"Enter search term: \")\n",
    "feature_3 = input(\"Enter search location: \")\n",
    "feature_4 = input(\"Enter description tokens: \")\n",
    "feature_5 = input(\"Enter year: \")\n",
    "feature_6 = input(\"Enter month: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f43671b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features into input sequence\n",
    "input_sequence = f\"{feature_1} {feature_2} {feature_3} {feature_4} {feature_5} {feature_6}\"\n",
    "\n",
    "# Convert string features to tokenized sequences\n",
    "input_sequence_sequence = tokenizer.texts_to_sequences([input_sequence])\n",
    "\n",
    "# Pad the sequence\n",
    "input_sequence_padded = pad_sequences(np.array(input_sequence_sequence), maxlen=2785, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caef4a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2785)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbe7569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 07:51:55.372002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:51:55.374970: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:51:55.377227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 583ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 07:51:55.964917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:51:55.967699: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:51:55.969745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 462ms/step\n",
      "0.5229401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 07:51:56.530493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-26 07:51:56.533155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-26 07:51:56.535103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 454ms/step\n",
      "0.13054784\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.031892907\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029056767\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.03224207\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.029377235\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.031704705\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.029511541\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.030115312\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029505117\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.031116618\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029496705\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.03141796\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.029498577\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.031028701\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.02953434\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029866349\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.0295267\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.030469814\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029447576\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.032001372\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.0295602\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029647335\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.029508607\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "0.031262085\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "0.029441452\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.03222375\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029542554\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.030146683\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029528381\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.030881885\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.029594464\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.029210862\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.03628264\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.029467842\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.03224995\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.029526288\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.030583683\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.02958089\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.02988103\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.029591164\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.029195288\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.036495455\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029534576\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.031088844\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029563097\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.029602695\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.029486679\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.031333838\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.029513396\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.030887533\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "0.029585976\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.029373046\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029529281\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.030542234\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029556489\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029316254\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "0.029560445\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.029708728\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.029493352\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.031007707\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.029567443\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.029743684\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029508313\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.03115088\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "0.029535888\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.031047186\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.029547386\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.030372977\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.02944404\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.03275211\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "0.029512186\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.031175612\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.029619\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029226543\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.03613768\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.029547432\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029701922\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029522736\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.03053216\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029502023\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.031684294\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.029577384\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.030111676\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.02953177\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.030711835\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.029415924\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0.03331846\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.02958994\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.029490864\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.029563278\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.029576797\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.029533932\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.030736364\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.02958244\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.02955274\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029590538\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.029234571\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.029507488\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "0.031204406\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.029544849\n",
      "mclean ormat dae data ibrd data enjoy data sqlexcellent data inventive data multitasks data customdesigned data vacationsick data looing data ansi data nodejs data granular data novice data 163415annually data skillsother data data coldhot data descent data beaucoup data onlu data data lenvoi data excelgooglesheets data 60549 data 11a data printerlogic data alvaria data reader data 18008336384 data filesemployersposter data forwardlooking data li data 8888381020 data bmchp data ffs data std data employerpaid data data tempo data communityhealth data quantexa data brings data ocr data hedge data uncovered data intrinsic data jobspecific data enterprisescale data preventminimize data maximise data alsodata data\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "generated_text = generate_text(input_sequence_padded)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af2ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
