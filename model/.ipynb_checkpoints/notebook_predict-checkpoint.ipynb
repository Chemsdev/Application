{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9fbe01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# plot en 3D \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# preprocessing data\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Import des librairies \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# plot en 3D \n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "# preprocessing data\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# clustering models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52da3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des données\n",
    "df = pd.read_csv('data/gsearch_jobs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33400b33",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118bacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396148a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd640403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d730a6c",
   "metadata": {},
   "source": [
    "### NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd92a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nan(df):\n",
    "    \n",
    "    nan_counts = df.isna().sum() # compte le nombre de NaN pour chaque colonne\n",
    "    total_counts = len(df) # compte le nombre total de données dans le dataframe\n",
    "    nan_percentages = (nan_counts / total_counts) * 100 # calcule le pourcentage de NaN pour chaque colonne\n",
    "    result_df = pd.concat([nan_counts, nan_percentages], axis=1) # combine les deux séries en un dataframe\n",
    "    result_df.columns = ['NaN Count', 'NaN Percentage'] # renomme les colonnes du nouveau dataframe\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NaN = count_nan(df)\n",
    "df_NaN = df_NaN.sort_values(by = ['NaN Count'], ascending = False)\n",
    "# df_NaN = df_NaN.loc[df_NaN['NaN Count'] != 0]\n",
    "df_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer les colonnes qui ont trop de NaN\n",
    "def no_NaN(df, treshold):\n",
    "    \n",
    "    nan_counts = df.isna().sum() # compte le nombre de NaN pour chaque colonne\n",
    "    total_counts = len(df) # compte le nombre total de données dans le dataframe\n",
    "    nan_percentages = (nan_counts / total_counts) * 100 # calcule le pourcentage de NaN pour chaque colonne\n",
    "    nan_treshold = nan_percentages[nan_percentages.values < treshold]\n",
    "    \n",
    "    return df[nan_treshold.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = no_NaN(df, 50)\n",
    "lin = lin.dropna()\n",
    "lin.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = lin.sample(n=2000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f61730f",
   "metadata": {},
   "source": [
    "### duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bbb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e54e67",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7fc995",
   "metadata": {},
   "source": [
    "L'objectif ici est de préparer les données pour notre modèle de ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef466b15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lin[\"description\"].unique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a43846",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin[\"extensions\"].unique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c106c2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin[\"description_tokens\"].unique()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f793dd",
   "metadata": {},
   "source": [
    "Ces trois colonnes fournissent des informations importante pour notre futur modèle, mais maintenant il faut les préparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = lin[[\"description\", \"extensions\", \"description_tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2423757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"description\", \"extensions\", \"description_tokens\"]:\n",
    "    print(f\"**********{i}************\\n, {df_prep[i].unique()[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37988bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text \n",
    "def clean_text(text): \n",
    "    # remove non_words and convert to lowercase \n",
    "    text = re.sub(r'\\W+', ' ', text.lower())\n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the 3 columns\n",
    "df_prep[\"description_clean\"] = df_prep[\"description\"].apply(clean_text)\n",
    "df_prep[\"extensions_clean\"] = df_prep[\"extensions\"].apply(clean_text)\n",
    "df_prep[\"description_tokens_clean\"] = df_prep[\"description_tokens\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ff957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"description_clean\", \"extensions_clean\", \"description_tokens_clean\"]:\n",
    "    print(f\"**********{i}************\\n, {df_prep[i].unique()[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94575332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_prep[\"description_tokens\"] = df_prep[\"description_clean\"].apply(nltk.word_tokenize)\n",
    "df_prep[\"description_tokens\"] = df_prep[\"description_tokens\"].apply(lambda tokens: [token for token in tokens if not token in stop_words])\n",
    "\n",
    "df_prep[\"extensions_tokens\"] = df_prep[\"extensions_clean\"].apply(nltk.word_tokenize)\n",
    "df_prep[\"extensions_tokens\"] = df_prep[\"extensions_tokens\"].apply(lambda tokens: [token for token in tokens if not token in stop_words])\n",
    "\n",
    "df_prep[\"description_tokens_tokens\"] = df_prep[\"description_tokens_clean\"].apply(nltk.word_tokenize)\n",
    "df_prep[\"description_tokens_tokens\"] = df_prep[\"description_tokens_tokens\"].apply(lambda tokens: [token for token in tokens if not token in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43883a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"description_tokens\", \"extensions_tokens\", \"description_tokens_tokens\"]:\n",
    "    print(f\"**********{i}************\\n, {list(df_prep[i].apply(tuple).unique().tolist()[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd33407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# define function for lemmatization\n",
    "def lemmatize_text(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15928f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "df_prep[\"description_tokens_lemmatized\"] = df_prep[\"description_tokens\"].apply(lemmatize_text)\n",
    "df_prep[\"extensions_tokens_lemmatized\"] = df_prep[\"extensions_tokens\"].apply(lemmatize_text)\n",
    "df_prep[\"description_tokens_tokens_lemmatized\"] = df_prep[\"description_tokens_tokens\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fdb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word cloud of most frequent words\n",
    "all_words = [word for tokens in df_prep[\"description_tokens_lemmatized\"] for word in tokens]\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(' '.join(all_words))\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word cloud of most frequent words\n",
    "all_words = [word for tokens in df_prep[\"extensions_tokens_lemmatized\"] for word in tokens]\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(' '.join(all_words))\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4625ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word cloud of most frequent words\n",
    "all_words = [word for tokens in df_prep[\"description_tokens_tokens_lemmatized\"] for word in tokens]\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(' '.join(all_words))\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf420b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word embeddings with TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df_prep[\"description_clean\"])\n",
    "embeddings_description = tfidf.transform(df_prep[\"description_clean\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08891e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac967165",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(df_prep[\"extensions_clean\"])\n",
    "embeddings_extensions = tfidf.transform(df_prep[\"extensions_clean\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(df_prep[\"description_tokens_clean\"])\n",
    "embeddings_description_tokens = tfidf.transform(df_prep[\"description_tokens_clean\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# concatenate embeddings\n",
    "all_embeddings_v1 = np.concatenate([embeddings_description, embeddings_extensions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.concatenate([all_embeddings_v1, embeddings_description_tokens], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Word2Vec model\n",
    "embedding_train = Word2Vec(df_prep[\"description_tokens\"], min_count=1, size=20)\n",
    "\n",
    "# Get the word embeddings for each words\n",
    "embeddings = []\n",
    "for word in embedding_train.wv.vocab:\n",
    "    embeddings.append(embedding_train.wv[word])\n",
    "\n",
    "# Create a dataframe with the embeddings\n",
    "embeddings_df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a523bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd9408",
   "metadata": {},
   "source": [
    "### Reduction de dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098fa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform t-SNE\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4eaa14",
   "metadata": {},
   "source": [
    "### préparation du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c913e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(embeddings_tsne, columns=['Component 1', 'Component 2', 'Component 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4803ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.lmplot(x='Component 1',\n",
    "#            y='Component 2',\n",
    "#            data=tsne_df,\n",
    "#            fit_reg=False,\n",
    "#            legend=True,\n",
    "#            height=9,\n",
    "# #            hue='Label',\n",
    "#            scatter_kws={\"s\":200, \"alpha\":0.3})\n",
    "\n",
    "# plt.title('t-SNE Results: Digits', weight='bold').set_fontsize(6)\n",
    "# plt.xlabel('Component 1')\n",
    "# plt.ylabel('Component 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370abc88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trace = go.Scatter3d(\n",
    "    x=tsne_df['Component 1'],\n",
    "    y=tsne_df['Component 2'],\n",
    "    z=tsne_df['Component 3'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5fe04",
   "metadata": {},
   "source": [
    "Conclusion du t-SNE : des components pas très explicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057677f",
   "metadata": {},
   "source": [
    "### Clustering : 1st model : Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AC = AgglomerativeClustering(n_clusters=3, metric = 'l2', linkage='complete')\n",
    "\n",
    "labels = model_AC.fit_predict(tsne_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le coefficient de silhouette pour chaque point\n",
    "silhouette_vals = silhouette_samples(tsne_df, labels)\n",
    "\n",
    "# Calculer la silhouette moyenne pour le dataset\n",
    "silhouette_avg = np.mean(silhouette_vals)\n",
    "\n",
    "# Tracer le diagramme de silhouette\n",
    "y_ticks = []\n",
    "y_lower, y_upper = 0, 0\n",
    "for i, cluster in enumerate(np.unique(labels)):\n",
    "    cluster_silhouette_vals = silhouette_vals[labels == cluster]\n",
    "    cluster_silhouette_vals.sort()\n",
    "    y_upper += len(cluster_silhouette_vals)\n",
    "    plt.barh(range(y_lower, y_upper), cluster_silhouette_vals, height=1)\n",
    "    y_ticks.append((y_lower + y_upper) / 2.)\n",
    "    y_lower += len(cluster_silhouette_vals)\n",
    "sns.set_theme(context='talk', style='darkgrid', palette='deep', font='sans-serif', \n",
    "                  font_scale=1, color_codes=True, rc=None)\n",
    "plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "plt.yticks(y_ticks, np.unique(labels))\n",
    "plt.ylabel('Cluster')\n",
    "plt.xlabel('Coefficient de silhouette')\n",
    "plt.show()\n",
    "print(\"Silhouette Score :\",silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1 = 'Component 1'\n",
    "feat2 = 'Component 2'\n",
    "\n",
    "\n",
    "# Create a DataFrame with the two features and the cluster labels\n",
    "df_1 = pd.DataFrame({'x': tsne_df[feat1], 'y': tsne_df[feat2], 'label': labels})\n",
    "\n",
    "# Get a list of the unique cluster labels\n",
    "clusters = df_1['label'].unique()\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data points for each cluster\n",
    "for cluster in clusters:\n",
    "    data = df_1[df_1['label'] == cluster]\n",
    "    ax.scatter(data['x'], data['y'], label=f'Cluster {cluster}')\n",
    "\n",
    "# Add legend and axis labels\n",
    "# ax.legend(labels=[\"Promising\",\"G.O.A.T\"])\n",
    "ax.set_xlabel(feat1)\n",
    "ax.set_ylabel(feat2)\n",
    "ax.set_title('Agglomerative Clustering')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "feat1 = 'Component 1'\n",
    "feat2 = 'Component 2'\n",
    "feat3 = 'Component 3'\n",
    "\n",
    "# Create a DataFrame with the three features and the cluster labels\n",
    "df_1 = pd.DataFrame({'x': tsne_df[feat1], 'y': tsne_df[feat2], 'z': tsne_df[feat3], 'label': labels})\n",
    "\n",
    "# Get a list of the unique cluster labels\n",
    "clusters = df_1['label'].unique()\n",
    "\n",
    "# Set up the plot\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points for each cluster\n",
    "for cluster in clusters:\n",
    "    data = df_1[df_1['label'] == cluster]\n",
    "    ax.scatter(data['x'], data['y'], data['z'], label=f'Cluster {cluster}')\n",
    "\n",
    "# Add legend and axis labels\n",
    "# ax.legend(labels=[\"Promising\",\"G.O.A.T\"])\n",
    "ax.set_xlabel(feat1)\n",
    "ax.set_ylabel(feat2)\n",
    "ax.set_zlabel(feat3)\n",
    "ax.set_title('Agglomerative Clustering')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the three features and the cluster labels\n",
    "df_3d = pd.DataFrame({'x': tsne_df['Component 1'], 'y': tsne_df['Component 2'], 'z': tsne_df['Component 3'], 'label': labels})\n",
    "\n",
    "# Create the plot\n",
    "fig = px.scatter_3d(df_3d, x='x', y='y', z='z', color='label')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9212d65",
   "metadata": {},
   "source": [
    "### 2nd model : KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d052aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering\n",
    "model_kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels_kmeans = model_kmeans.fit_predict(tsne_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba849b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculer le coefficient de silhouette pour chaque point\n",
    "# silhouette_vals = silhouette_samples(tsne_df, labels_kmeans)\n",
    "\n",
    "# # Calculer la silhouette moyenne pour le dataset\n",
    "# silhouette_avg = np.mean(silhouette_vals)\n",
    "\n",
    "# # Tracer le diagramme de silhouette\n",
    "# y_ticks = []\n",
    "# y_lower, y_upper = 0, 0\n",
    "# for i, cluster in enumerate(np.unique(labels_kmeans)):\n",
    "#     cluster_silhouette_vals = silhouette_vals[labels_kmeans == cluster]\n",
    "#     cluster_silhouette_vals.sort()\n",
    "#     y_upper += len(cluster_silhouette_vals)\n",
    "#     plt.barh(range(y_lower, y_upper), cluster_silhouette_vals, height=1)\n",
    "#     y_ticks.append((y_lower + y_upper) / 2.)\n",
    "#     y_lower += len(cluster_silhouette_vals)\n",
    "# sns.set_theme(context='talk', style='darkgrid', palette='deep', font='sans-serif', \n",
    "#                   font_scale=1, color_codes=True, rc=None)\n",
    "# plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "# plt.yticks(y_ticks, np.unique(labels))\n",
    "# plt.ylabel('Cluster')\n",
    "# plt.xlabel('Coefficient de silhouette')\n",
    "# plt.show()\n",
    "# print(\"Silhouette Score :\",silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the three features and the cluster labels\n",
    "df_3d = pd.DataFrame({'x': tsne_df['Component 1'], 'y': tsne_df['Component 2'], 'z': tsne_df['Component 3'], 'label': labels_kmeans})\n",
    "\n",
    "# Create the plot\n",
    "fig = px.scatter_3d(df_3d, x='x', y='y', z='z', color='label')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f6c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
