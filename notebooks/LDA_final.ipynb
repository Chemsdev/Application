{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5951e385",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: RGB(203, 192, 225);\" >\n",
    "<h1 style=\"margin: auto; padding: 30px; \">Notebook extracting trends LDA</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c2a2c",
   "metadata": {},
   "source": [
    "Objectif : Extracting the main topics from your dataset using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3bbd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des librairies\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# preprocessing data\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# pip install gensim\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80f81cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>commute_time</th>\n",
       "      <th>salary_pay</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst (Risk Adjustment Consulting Resea...</td>\n",
       "      <td>Cambia Health Solutions, Inc</td>\n",
       "      <td>United States</td>\n",
       "      <td>via Datafloq</td>\n",
       "      <td>Are you looking for a new job? Check out this ...</td>\n",
       "      <td>['3 hours ago', 'Full-time', 'No degree mentio...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgKFJpc2sgQW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DATA ANALYST II</td>\n",
       "      <td>Lumen</td>\n",
       "      <td>United States</td>\n",
       "      <td>via ComputerJobs.com</td>\n",
       "      <td>About Lumen\\nLumen is guided by our belief tha...</td>\n",
       "      <td>['17 hours ago', 'Full-time', 'No degree menti...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEQVRBIEFOQUxZU1QgSUkiLCJodG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['excel', 'sql', 'powerpoint', 'power_bi', 'sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst - Swisslog</td>\n",
       "      <td>Swisslog</td>\n",
       "      <td>United States</td>\n",
       "      <td>via Swisslog</td>\n",
       "      <td>Data Analyst Mason, Ohio With guidance from se...</td>\n",
       "      <td>['4 hours ago', 'Full-time', 'Health insurance...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgLSBTd2lzc2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python', 'r', 'sql', 'powerpoint', 'word', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst - Secret clearance - Remote Remot...</td>\n",
       "      <td>General Dynamics Information Technology</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>REQ#: RQ135670 Travel Required: None Public Tr...</td>\n",
       "      <td>['11 hours ago', 'Work from home', 'Full-time'...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgLSBTZWNyZX...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['t-sql', 'pl/sql', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Collections Data Analyst (921071)</td>\n",
       "      <td>Purpose Financial</td>\n",
       "      <td>United States</td>\n",
       "      <td>via Jobs At Purpose Financial / Advance Americ...</td>\n",
       "      <td>Address : 135 N Church Street, Spartanburg, So...</td>\n",
       "      <td>['20 hours ago', 'Full-time', 'Health insuranc...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJDb2xsZWN0aW9ucyBEYXRhIEFuYW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python', 'r', 'sas', 'sql']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                              title   \n",
       "0           0      0  Data Analyst (Risk Adjustment Consulting Resea...  \\\n",
       "1           1      1                                    DATA ANALYST II   \n",
       "2           2      2                            Data Analyst - Swisslog   \n",
       "3           3      3  Data Analyst - Secret clearance - Remote Remot...   \n",
       "4           4      4                  Collections Data Analyst (921071)   \n",
       "\n",
       "                              company_name       location   \n",
       "0             Cambia Health Solutions, Inc  United States  \\\n",
       "1                                    Lumen  United States   \n",
       "2                                 Swisslog  United States   \n",
       "3  General Dynamics Information Technology       Anywhere   \n",
       "4                        Purpose Financial  United States   \n",
       "\n",
       "                                                 via   \n",
       "0                                       via Datafloq  \\\n",
       "1                               via ComputerJobs.com   \n",
       "2                                       via Swisslog   \n",
       "3                                 via Clearance Jobs   \n",
       "4  via Jobs At Purpose Financial / Advance Americ...   \n",
       "\n",
       "                                         description   \n",
       "0  Are you looking for a new job? Check out this ...  \\\n",
       "1  About Lumen\\nLumen is guided by our belief tha...   \n",
       "2  Data Analyst Mason, Ohio With guidance from se...   \n",
       "3  REQ#: RQ135670 Travel Required: None Public Tr...   \n",
       "4  Address : 135 N Church Street, Spartanburg, So...   \n",
       "\n",
       "                                          extensions   \n",
       "0  ['3 hours ago', 'Full-time', 'No degree mentio...  \\\n",
       "1  ['17 hours ago', 'Full-time', 'No degree menti...   \n",
       "2  ['4 hours ago', 'Full-time', 'Health insurance...   \n",
       "3  ['11 hours ago', 'Work from home', 'Full-time'...   \n",
       "4  ['20 hours ago', 'Full-time', 'Health insuranc...   \n",
       "\n",
       "                                              job_id   \n",
       "0  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgKFJpc2sgQW...  \\\n",
       "1  eyJqb2JfdGl0bGUiOiJEQVRBIEFOQUxZU1QgSUkiLCJodG...   \n",
       "2  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgLSBTd2lzc2...   \n",
       "3  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgLSBTZWNyZX...   \n",
       "4  eyJqb2JfdGl0bGUiOiJDb2xsZWN0aW9ucyBEYXRhIEFuYW...   \n",
       "\n",
       "                                           thumbnail  ... commute_time   \n",
       "0                                                NaN  ...          NaN  \\\n",
       "1                                                NaN  ...          NaN   \n",
       "2  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "3  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "4                                                NaN  ...          NaN   \n",
       "\n",
       "  salary_pay salary_rate salary_avg salary_min salary_max salary_hourly   \n",
       "0        NaN         NaN        NaN        NaN        NaN           NaN  \\\n",
       "1        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "2        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "3        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "4        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "\n",
       "   salary_yearly salary_standardized   \n",
       "0            NaN                 NaN  \\\n",
       "1            NaN                 NaN   \n",
       "2            NaN                 NaN   \n",
       "3            NaN                 NaN   \n",
       "4            NaN                 NaN   \n",
       "\n",
       "                                  description_tokens  \n",
       "0                                                 []  \n",
       "1  ['excel', 'sql', 'powerpoint', 'power_bi', 'sh...  \n",
       "2  ['python', 'r', 'sql', 'powerpoint', 'word', '...  \n",
       "3                         ['t-sql', 'pl/sql', 'sql']  \n",
       "4                      ['python', 'r', 'sas', 'sql']  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import des donnÃ©es\n",
    "df = pd.read_csv('data/gsearch_jobs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b6ff30",
   "metadata": {},
   "source": [
    "<div style=\"background-color: RGB(165, 195, 186);\" >\n",
    "<h2 style=\"margin: auto; padding: 20px; color:#fff; \">EDA</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d14e4f",
   "metadata": {},
   "source": [
    "### NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab188e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nan(df):\n",
    "    \n",
    "    nan_counts = df.isna().sum() # compte le nombre de NaN pour chaque colonne\n",
    "    total_counts = len(df) # compte le nombre total de donnÃ©es dans le dataframe\n",
    "    nan_percentages = (nan_counts / total_counts) * 100 # calcule le pourcentage de NaN pour chaque colonne\n",
    "    result_df = pd.concat([nan_counts, nan_percentages], axis=1) # combine les deux sÃ©ries en un dataframe\n",
    "    result_df.columns = ['NaN Count', 'NaN Percentage'] # renomme les colonnes du nouveau dataframe\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36596a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Count</th>\n",
       "      <th>NaN Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commute_time</th>\n",
       "      <td>17977</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_yearly</th>\n",
       "      <td>16525</td>\n",
       "      <td>91.923013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_hourly</th>\n",
       "      <td>15966</td>\n",
       "      <td>88.813484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_max</th>\n",
       "      <td>14720</td>\n",
       "      <td>81.882405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_min</th>\n",
       "      <td>14720</td>\n",
       "      <td>81.882405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>14508</td>\n",
       "      <td>80.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_standardized</th>\n",
       "      <td>14508</td>\n",
       "      <td>80.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_avg</th>\n",
       "      <td>14508</td>\n",
       "      <td>80.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_rate</th>\n",
       "      <td>14508</td>\n",
       "      <td>80.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_pay</th>\n",
       "      <td>14508</td>\n",
       "      <td>80.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_from_home</th>\n",
       "      <td>9836</td>\n",
       "      <td>54.714357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbnail</th>\n",
       "      <td>9063</td>\n",
       "      <td>50.414418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_type</th>\n",
       "      <td>115</td>\n",
       "      <td>0.639706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>15</td>\n",
       "      <td>0.083440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_location</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_term</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_at</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extensions</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>via</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NaN Count  NaN Percentage\n",
       "commute_time             17977      100.000000\n",
       "salary_yearly            16525       91.923013\n",
       "salary_hourly            15966       88.813484\n",
       "salary_max               14720       81.882405\n",
       "salary_min               14720       81.882405\n",
       "salary                   14508       80.703121\n",
       "salary_standardized      14508       80.703121\n",
       "salary_avg               14508       80.703121\n",
       "salary_rate              14508       80.703121\n",
       "salary_pay               14508       80.703121\n",
       "work_from_home            9836       54.714357\n",
       "thumbnail                 9063       50.414418\n",
       "schedule_type              115        0.639706\n",
       "location                    15        0.083440\n",
       "search_location              0        0.000000\n",
       "Unnamed: 0                   0        0.000000\n",
       "date_time                    0        0.000000\n",
       "search_term                  0        0.000000\n",
       "index                        0        0.000000\n",
       "posted_at                    0        0.000000\n",
       "job_id                       0        0.000000\n",
       "extensions                   0        0.000000\n",
       "description                  0        0.000000\n",
       "via                          0        0.000000\n",
       "company_name                 0        0.000000\n",
       "title                        0        0.000000\n",
       "description_tokens           0        0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NaN = count_nan(df)\n",
    "df_NaN = df_NaN.sort_values(by = ['NaN Count'], ascending = False)\n",
    "# df_NaN = df_NaN.loc[df_NaN['NaN Count'] != 0]\n",
    "df_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef67b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer les colonnes qui ont trop de NaN\n",
    "def no_NaN(df, treshold):\n",
    "    \n",
    "    nan_counts = df.isna().sum() # compte le nombre de NaN pour chaque colonne\n",
    "    total_counts = len(df) # compte le nombre total de donnÃ©es dans le dataframe\n",
    "    nan_percentages = (nan_counts / total_counts) * 100 # calcule le pourcentage de NaN pour chaque colonne\n",
    "    nan_treshold = nan_percentages[nan_percentages.values < treshold]\n",
    "    \n",
    "    return df[nan_treshold.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21358214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "index                 0\n",
       "title                 0\n",
       "company_name          0\n",
       "location              0\n",
       "via                   0\n",
       "description           0\n",
       "extensions            0\n",
       "job_id                0\n",
       "posted_at             0\n",
       "schedule_type         0\n",
       "search_term           0\n",
       "date_time             0\n",
       "search_location       0\n",
       "description_tokens    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df version 2\n",
    "df_v2 = no_NaN(df, 50)\n",
    "df_v2 = df_v2.dropna()\n",
    "df_v2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9e813",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb0fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "df_train, df_test = train_test_split(df_v2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7295774",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: RGB(165, 195, 186);\" >\n",
    "<h2 style=\"margin: auto; padding: 20px; color:#fff; \">Extracting Topics using LDA in Python</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "700a2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©cupÃ©rer la colonne \"description\" sous forme de liste\n",
    "description_list = df_train[\"description\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67666dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0088db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a function to perform the pre processing steps on the entire dataset\n",
    "'''\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d00e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er une liste pour stocker les rÃ©sultats\n",
    "processed_text = []\n",
    "\n",
    "# Appliquer la fonction lemmatize_stemming Ã  chaque Ã©lÃ©ment de la liste description_list\n",
    "for text in description_list:\n",
    "    processed_text.append(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bcc9b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'help', 'data', 'analysi', 'qualit', 'research', 'nvivo']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preview 'processed_docs'\n",
    "'''\n",
    "print(processed_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f91f80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dictionary from 'processed_docs' containing the number of times a word appears \n",
    "in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
    "'''\n",
    "dictionary = gensim.corpora.Dictionary(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc3cbaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 analysi\n",
      "1 data\n",
      "2 help\n",
      "3 need\n",
      "4 nvivo\n",
      "5 qualit\n",
      "6 research\n",
      "7 confirmatori\n",
      "8 determin\n",
      "9 excel\n",
      "10 indic\n",
      "11 relationship\n",
      "12 sensit\n",
      "13 sheet\n",
      "14 specif\n",
      "15 statstic\n",
      "16 accomplish\n",
      "17 accord\n",
      "18 account\n",
      "19 accuraci\n",
      "20 achiev\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Checking dictionary created\n",
    "'''\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b46617",
   "metadata": {},
   "source": [
    "- less than no_below documents (absolute number) or\n",
    "- more than no_above documents (fraction of total corpus size, not absolute number).\n",
    "- after (1) and (2), keep only the first keep_n most frequent tokens (or keep all if None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392415bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "OPTIONAL STEP\n",
    "Remove very rare and ver common words:\n",
    "\n",
    "- words appearing less than 15 times\n",
    "- words appearing in more than 10% of all documents\n",
    "'''\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to 'bow_corpus'\n",
    "'''\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preview BOW for our sample preprocessed document\n",
    "'''\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11283820",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: RGB(165, 195, 186);\" >\n",
    "<h2 style=\"margin: auto; padding: 20px; color:#fff; \">Running LDA using Bag of Words</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA mono-core -- fallback code in case LdaMulticore throws an error on your machine\n",
    "# lda_model = gensim.models.LdaModel(bow_corpus, \n",
    "#                                    num_topics = 10, \n",
    "#                                    id2word = dictionary,                                    \n",
    "#                                    passes = 50)\n",
    "\n",
    "# LDA multicore \n",
    "'''\n",
    "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
    "'''\n",
    "# TODO\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 8, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13982912",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "'''\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b11301",
   "metadata": {},
   "source": [
    "## Classification of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317556d8",
   "metadata": {},
   "source": [
    "Quelques suggestions de noms pour chaque topic basÃ©es sur les mots et les poids correspondants : \n",
    "\n",
    "- Topic 0: CarriÃ¨res dans la publication et l'Ã©dition\n",
    "- Topic 1: Assurance et remboursement mÃ©dical\n",
    "- Topic 2: Marketing et publicitÃ© en ligne\n",
    "- Topic 3: Ã‰ducation et Ã©tudes universitaires\n",
    "- Topic 4: Recherche mÃ©dicale et scientifique\n",
    "- Topic 5: Logistique et transport\n",
    "- Topic 6: Informatique et rÃ©solution de problÃ¨mes\n",
    "- Topic 7: Finance et gestion des actifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256a7df",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37477c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er un dataframe avec les informations des topics\n",
    "topics_df = pd.DataFrame({\n",
    "    'Topic': [\"CarriÃ¨res dans la publication et l'Ã©dition\", 'Assurance et remboursement mÃ©dical', \n",
    "              'Marketing et publicitÃ© en ligne', 'Ã‰ducation et Ã©tudes universitaires', \n",
    "              'Recherche mÃ©dicale et scientifique', 'Logistique et transport',\n",
    "              'Informatique et rÃ©solution de problÃ¨mes', 'Finance et gestion des actifs'],\n",
    "    'Words': [\n",
    "        'jone, edward, fortun, firm, branch, rank, magazin, publish, rat, obtain',\n",
    "        'claim, centen, clinic, purchas, reimburs, elev, stock, pharmacie, root, tuition',\n",
    "        'brand, media, websit, campaign, event, looker, consum, love, tech, tulsa',\n",
    "        'univers, student, school, studi, survey, colleg, check, academ, institut, date',\n",
    "        'clinic, suppli, machin, chain, patient, walmart, predict, scientist, algorithm, energi',\n",
    "        'resum, agenc, capac, day, transport, send, forward, ongo, orchestr, readi',\n",
    "        'oracl, map, file, troubleshoot, server, agil, resolv, flow, vendor, travel',\n",
    "        'vaccin, bank, covid, audit, citi, asset, investig, architectur, azur, legal'\n",
    "    ],\n",
    "    'Weight': [\n",
    "        [0.059, 0.052, 0.047, 0.045, 0.040, 0.033, 0.026, 0.025, 0.025, 0.024],\n",
    "        [0.021, 0.016, 0.013, 0.012, 0.012, 0.012, 0.012, 0.012, 0.011, 0.010],\n",
    "        [0.007, 0.007, 0.006, 0.006, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005],\n",
    "        [0.016, 0.014, 0.009, 0.008, 0.008, 0.007, 0.007, 0.006, 0.006, 0.005],\n",
    "        [0.014, 0.010, 0.010, 0.009, 0.009, 0.008, 0.008, 0.008, 0.006, 0.006],\n",
    "        [0.031, 0.021, 0.017, 0.017, 0.016, 0.015, 0.013, 0.013, 0.013, 0.013],\n",
    "        [0.008, 0.007, 0.006, 0.006, 0.006, 0.005, 0.005, 0.005, 0.004, 0.004],\n",
    "        [0.010, 0.009, 0.006, 0.006, 0.005, 0.005, 0.005, 0.005, 0.005, 0.004]\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea9f7f",
   "metadata": {},
   "source": [
    "### Exporter le topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = topics_df.to_csv(\"data/topics_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all words\n",
    "all_words = [word for words_list in topics_df['Words'] for word in words_list.split(\", \")]\n",
    "\n",
    "# Create a list of all weights\n",
    "all_weights = [weight for weight_list in topics_df['Weight'] for weight in weight_list]\n",
    "\n",
    "# Create a list of topics for each word\n",
    "topic_labels = []\n",
    "for i, words_list in enumerate(topics_df['Words']):\n",
    "    num_words = len(words_list.split(\", \"))\n",
    "    topic_labels.extend([topics_df['Topic'][i]] * num_words)\n",
    "    \n",
    "# Create hover text with words and topics\n",
    "hover_text = [f\"Word: {word}<br>Topic: {topic}\" for word, topic in zip(all_words, topic_labels)]\n",
    "\n",
    "# Create a Scatter3d trace with the data\n",
    "scatter3d_trace = go.Scatter3d(\n",
    "    x=list(range(len(all_words))),\n",
    "    y=[0] * len(all_words),\n",
    "    z=all_weights,\n",
    "    text=all_words,\n",
    "    hovertemplate=\"%{text}<br><br>%{hovertext}\",\n",
    "    hovertext=hover_text,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=[weight * 1000 for weight in all_weights],\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create a Scatter3d trace with the data\n",
    "scatter3d_trace = go.Scatter3d(\n",
    "    x=list(range(len(all_words))),\n",
    "    y=[0] * len(all_words),\n",
    "    z=all_weights,\n",
    "    text=all_words,\n",
    "    hovertext=topic_labels,  # Assign the topic labels as hovertext\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=[weight * 1000 for weight in all_weights],\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "    \n",
    "# Create a Figure object and add the trace\n",
    "fig = go.Figure(data=[scatter3d_trace])\n",
    "\n",
    "# Configure the layout\n",
    "fig.update_layout(\n",
    "    title='Scatter Plot 3D - Mots et poids',\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            title='Mots',\n",
    "            tickfont=dict(color='white'),\n",
    "            title_font=dict(color='white')\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Y',\n",
    "            tickfont=dict(color='white'),\n",
    "            title_font=dict(color='white')\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title='Poids',\n",
    "            tickfont=dict(color='white'),\n",
    "            title_font=dict(color='white')\n",
    "        ),\n",
    "        bgcolor='black'\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    plot_bgcolor='black'\n",
    ")    \n",
    "  \n",
    "# Show the interactive figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
